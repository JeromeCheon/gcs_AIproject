{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 사용 패키지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import argparse\n",
    "import easydict\n",
    "from torch import autograd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils import data\n",
    "from torchvision import datasets, transforms\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = pd.read_csv('./data/한국가스공사_시간별 공급량_20181231.csv', encoding='cp949')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(total.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total['구분'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_map = {}\n",
    "for i, d in enumerate(total['구분'].unique()):\n",
    "    d_map[d] = i\n",
    "total['구분'] = total['구분'].map(d_map) # 이 과정은 A~H 까지의 알파벳을 숫자로 매핑(대치)시키는 과정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total['구분']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total['연월일'] = pd.to_datetime(total['연월일']) # 시계열 데이터로"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# 한글 폰트 사용을 위해서 세팅\n",
    "from matplotlib import font_manager, rc\n",
    "font_path = \"/USER/d2coding.ttf\"\n",
    "font = font_manager.FontProperties(fname=font_path).get_name()\n",
    "rc('font', family=font)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 9))\n",
    "sns.lineplot(y=total['공급량'], x=total['연월일'])\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Supply')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이를 통해 매 겨울 시기에 공급량이 많았다는 것을 알 수 있다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total['year'] = total['연월일'].dt.year\n",
    "total['month'] = total['연월일'].dt.month\n",
    "total['day'] = total['연월일'].dt.day\n",
    "total['weekday'] = total['연월일'].dt.weekday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 연속형 변수인 공급량 컬럼은 따로 drop 하자\n",
    "scale_cols = ['공급량']\n",
    "cont_var = total[scale_cols]\n",
    "# total.drop(columns=['공급량'], inplace=True)\n",
    "etc = total.drop(columns=['공급량'])\n",
    "print(cont_var)\n",
    "print(etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 정규화: continuous variable\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "cont_var.sort_index(ascending=False).reset_index(drop=True)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "df_scaled = scaler.fit_transform(cont_var)\n",
    "df_scaled = pd.DataFrame(df_scaled)\n",
    "df_scaled.columns = scale_cols\n",
    "\n",
    "df_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = pd.concat([etc,df_scaled], axis=1)\n",
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pytorch lstm model 정의\n",
    "\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self, num_classes, input_size, hidden_size, num_layers):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers, batch_first=True)\n",
    "        # 상대적인 결과를 보고 감으로. 데이터가 많을 때는 레이어 수를 늘리는 게 보편적. \n",
    "        # 분류는 클래스 개수로 해야 나중에 softmax를 취할 수 있을 것 regression 해야 할 feature의 개수가 마지막 인자가 될 것. \n",
    "        # self.fc = nn.Sequential(\n",
    "        #     nn.Linear(hidden_size, 50),\n",
    "        #     nn.Linear(50, 30),\n",
    "        #     nn.Linear(30, 10),\n",
    "        #     # nn.Linear(10,1)\n",
    "        #     nn.Linear(10, num_classes)\n",
    "        # )\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "        # 마지막 달 값을 평균을 내면 하나의 값이 나올 건데, 평균값으로 뒤의 \n",
    "        # 맨 마지막 한달치 이런걸로 \n",
    "    def forward(self, x):\n",
    "        h_0 = Variable(torch.zeros(\n",
    "            self.num_layers, x.size(0), self.hidden_size).to(device))\n",
    "        c_0 = Variable(torch.zeros(\n",
    "            self.num_layers, x.size(0), self.hidden_size).to(device))\n",
    "        \n",
    "        # 학습 때 y가 같이 들어간 x일 것\n",
    "        ula, (h_out, _) = self.lstm(x, (h_0, c_0))\n",
    "        h_out = h_out.view(-1, self.hidden_size)\n",
    "        \n",
    "        out = self.fc(h_out)\n",
    "        return out\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_with_window(x, y, window_size):\n",
    "    x_list = []\n",
    "    y_list = []   \n",
    "    for i in range(len(x)-window_size):\n",
    "        x_list.append(np.array(x.iloc[i:(i+window_size)]))\n",
    "        if y != 0:\n",
    "            y_list.append(np.array(y.iloc[i+window_size]))\n",
    "    if y != 0:\n",
    "        return torch.FloatTensor(x_list).to(device), torch.FloatTensor(y_list).to(device).view([-1, 1])\n",
    "    else:\n",
    "        return torch.FloatTensor(x_list).to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['구분','year', 'month', 'day', 'weekday', '시간']\n",
    "label = ['공급량']\n",
    "train_years = [2013,2014,2015,2016,2017]\n",
    "val_years = [2018]\n",
    "test_size = len(total[total['year'].isin(val_years)])\n",
    "# 원래 윈도우 사이즈는 천단위, 만단위 는 쉽지 않고 몇백단위까지가 최대로 돌릴 수 있는 것\n",
    "# window_size = int(test_size/2) # 반년치의 데이터를 window_size로 정의하겠다. \n",
    "window_size = 24*30\n",
    "x = total[features]\n",
    "y = total[label]\n",
    "print(x.shape, y.shape)\n",
    "print(y)\n",
    "print(\"window_size:\", window_size)\n",
    "X, Y = dataset_with_window(x, y, window_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X)\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이제 train 과 val로 나눠줄 차례\n",
    "# 기준 length는 2018년도 데이터셋의 길이로 함\n",
    "X_train = X[:test_size]\n",
    "X_test = X[test_size:]\n",
    "y_train = Y[:test_size]\n",
    "y_test = Y[test_size:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.size())\n",
    "print(y_train.size())\n",
    "# 여기서 진짜 잘못했다.. .test_size를 잘못 설정을 했어."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_test.size())\n",
    "print(y_test.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 미니 배치 형식으로 맞춰줘\n",
    "# loader를 x, y 같이 붙여줄 필요가 없음\n",
    "\n",
    "# train 용은 x, y 두 개가 같이 들어가는 로더를 만들고\n",
    "# 테스트 로더를 x만 들어가게 한다음에 학습 돌릴 때 train time일 떄는 loader가 뱉어주는 값이 둘 다 있게 하고,\n",
    "# 테스트 때는 \n",
    "train = torch.utils.data.TensorDataset(X_train, y_train)\n",
    "test = torch.utils.data.TensorDataset(X_test, y_test)\n",
    "\n",
    "# 미니 배치가 너무 크면 학습이 덜 될수 있다. \n",
    "batch_size = 64\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train, batch_size=batch_size, shuffle=False)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameter config \n",
    "# 딥러닝 학습할 때는 미니 배치화해서 학습을 해야 한다. 지금은\n",
    "# 36만개를 통째로 넣고 있어서 문제가 있다. \n",
    "num_epochs = 2 # 200\n",
    "learning_rate = 0.1 #0.01\n",
    "\n",
    "input_size = 6\n",
    "hidden_size = 2\n",
    "num_layers = 1\n",
    "\n",
    "num_classes = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache() # PyTorch thing\n",
    "\n",
    "with torch.no_grad():\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTM(num_classes, input_size, hidden_size, num_layers).to(device)\n",
    "\n",
    "criterion = torch.nn.L1Loss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), learning_rate)\n",
    "# 일단 지금처럼 LSTM 하나라도 지금처럼 하고,\n",
    "# LSTM 레이어를 늘려보는 것도 다음 단계로 좋다. \n",
    "\n",
    "hist = np.zeros(num_epochs)    \n",
    "loss_graph = [] # 그래프 그릴 목적인 loss.\n",
    "n = len(train_loader)\n",
    "\n",
    "for t in range(num_epochs):   \n",
    "    \n",
    "    for data in train_loader:\n",
    "\n",
    "        seq, target = data # 배치 데이터.\n",
    "        # Forward pass\n",
    "        out = model(seq)   # 모델에 넣고,\n",
    "        loss = criterion(out, target) # output 가지고 loss 구하고,\n",
    "        hist[t] = loss.item()\n",
    "        \n",
    "        optimizer.zero_grad() # \n",
    "        loss.backward() # loss가 최소가 되게하는 \n",
    "        optimizer.step() # 가중치 업데이트 해주고,\n",
    "    # if t % 10 == 0 and t !=0:\n",
    "        print('[epoch: %d] MAE: %.4f'%(t, loss.item()))\n",
    "    # validation은?\n",
    "    # if t % 10 == 0:\n",
    "        # with torch.no_grad():\n",
    "            # 여기서 validation 해야해 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_DIR = '/USER/kaggle/2nd_inclass/'\n",
    "torch.save(model, os.path.join(MODEL_DIR, 'model.pt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 추론 및 결과 제출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('./data/test.csv')\n",
    "submission = pd.read_csv('./data/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['일자'] = test['일자|시간|구분'].str.split(' ').str[0]\n",
    "test['시간'] = test['일자|시간|구분'].str.split(' ').str[1].astype(int)\n",
    "test['구분'] = test['일자|시간|구분'].str.split(' ').str[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['일자'] = pd.to_datetime(test['일자'])\n",
    "test['year'] = test['일자'].dt.year\n",
    "test['month'] = test['일자'].dt.month\n",
    "test['day'] = test['일자'].dt.day\n",
    "test['weekday'] = test['일자'].dt.weekday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['구분'] = test['구분'].map(d_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x = test[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x = dataset_with_window(test_x, 0, window_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 추론\n",
    "model.eval()\n",
    "preds = model(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(preds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['공급량'] = preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('lstm1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nmae(true_df, pred_df):\n",
    "    target_idx = true_df.iloc[:,0]\n",
    "    pred_df = pred_df[pred_df.iloc[:,0].isin(target_idx)]\n",
    "    pred_df = pred_df.sort_values(by=[pred_df.columns[0]], ascending=[True])\n",
    "    true_df = true_df.sort_values(by=[true_df.columns[0]], ascending=[True])\n",
    "    \n",
    "    true = true_df.iloc[:,1].to_numpy()\n",
    "    pred = pred_df.iloc[:,1].to_numpy()\n",
    "    \n",
    "    score = np.mean((np.abs(true-pred))/true)\n",
    "    \n",
    "    return score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
