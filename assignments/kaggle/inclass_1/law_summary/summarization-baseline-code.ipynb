{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 과제 설명\n",
    "법률 문서에 대한 원문을 가장 잘 나타내는 3개의 문장을 추출하는 문서 요약 모델 개발\n",
    "    \n",
    "### 데이터 설명\n",
    "- 개요 : 뉴스 기사, 기고문, 잡지, 법률 (판결문) 등 다양한 영역에서 추출된 텍스트 데이터와 요약본 40만 건\n",
    "- 입출력: \n",
    "    - 입력: 문장별로 나뉜 법률 문서 원문, 예) 법률 문서 = [문장1, 문장2, ..., 문장K], K : 문서 길이\n",
    "    - 출력: 요약문에 포함될 문장 인덱스 3개\n",
    "- 데이터셋 구성\n",
    "    - 학습 데이터:\n",
    "        - train.json : 24,027개의 법률 문서 아이디 (id), 원문 (article_original), 요약문 (extractive)\n",
    "    - 테스트 데이터:\n",
    "        - test.json : 3,004개의 법률 문서 아이디 (id), 원문 (article_original)\n",
    "\n",
    "### 사용 pretrained 모델\n",
    " `beomi/KcELECTRA-base` \n",
    "[Documentation](https://github.com/Beomi/KcELECTRA)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 세팅\n",
    "### 라이브러리\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 설치되지 않은 라이브러리의 경우, 주석 해제 후 코드를 실행하여 설치\n",
    "# !pip install pytorch-pretrained-bert\n",
    "# !pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 라이브러리 및 코드 파일 불러오기\n",
    "import os\n",
    "import time\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from datetime import datetime, timezone, timedelta\n",
    "import numpy as np\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시드 고정\n",
    "RANDOM_SEED = 42\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(RANDOM_SEED)\n",
    "random.seed(RANDOM_SEED)\n",
    "\n",
    "# Set device\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# 경로 설정\n",
    "ROOT_PATH = '/USER/kaggle/1st_inclass/summary_data'\n",
    "DATA_DIR = '/USER/kaggle/1st_inclass/summary_data'\n",
    "MODEL_DIR = ROOT_PATH\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper-parameters\n",
    "TRAIN_BATCH_SIZE = 6\n",
    "EVAL_BATCH_SIZE = 4\n",
    "\n",
    "# 학습 데이터만 있으니 학습 데이터셋 비율과 validation 데이터셋 비율을 나눔\n",
    "TRAIN_RATIO = 0.8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `__init__` 에서 tokenizer는 transformers 라이브러리에서 AutoTokenizer를 사용합니다. 이 외에도 원하는 토크나이저를 적용해 다양한 실험을 진행할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from torch.utils.data import Dataset\n",
    "from pytorch_pretrained_bert import BertTokenizer\n",
    "from transformers import AutoTokenizer\n",
    "from itertools import chain\n",
    "import json\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data_dir, mode):\n",
    "        self.data_dir = data_dir\n",
    "        self.mode = mode\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(\"beomi/KcELECTRA-base\")\n",
    "        self.inputs, self.labels = self.data_loader()\n",
    "\n",
    "    def data_loader(self):\n",
    "        print('Loading ' + self.mode + ' dataset..')\n",
    "        \n",
    "        if os.path.isfile(os.path.join(self.data_dir, self.mode + '_X.pt')):\n",
    "            inputs = torch.load(os.path.join(self.data_dir, self.mode + '_X.pt'))\n",
    "            labels = torch.load(os.path.join(self.data_dir, self.mode + '_Y.pt'))\n",
    "\n",
    "        else:\n",
    "            file_path = os.path.join(self.data_dir, 'train.json')\n",
    "            df = pd.read_json(file_path, orient='records', encoding='utf-8-sig')\n",
    "          \n",
    "            if self.mode == 'train':\n",
    "                df = df.loc[:TRAIN_RATIO*int(len(df)), :]\n",
    "            elif self.mode == 'val':\n",
    "                df = df.loc[TRAIN_RATIO*int(len(df)):, :]\n",
    "\n",
    "            inputs = pd.DataFrame(columns=['src'])\n",
    "            labels = pd.DataFrame(columns=['trg'])\n",
    "            inputs['src'] =  df['article_original']\n",
    "            labels['trg'] =  df['extractive']\n",
    "          \n",
    "            # Preprocessing\n",
    "            inputs, labels = self.preprocessing(inputs, labels)\n",
    "            # Save data\n",
    "            torch.save(inputs ,os.path.join(self.data_dir, self.mode + '_X.pt'))\n",
    "            torch.save(labels, os.path.join(self.data_dir, self.mode + '_Y.pt'))\n",
    "\n",
    "        inputs = inputs.values\n",
    "        labels = labels.values\n",
    "\n",
    "        return inputs, labels\n",
    "\n",
    "    def pad(self, data, pad_id, max_len):\n",
    "        padded_data = data.map(lambda x : torch.cat([x, torch.tensor([pad_id] * (max_len - len(x)))]))\n",
    "        return padded_data\n",
    "\n",
    "    def preprocessing(self, inputs, labels):\n",
    "        print('Preprocessing ' + self.mode + ' dataset..')\n",
    "        #Encoding original text\n",
    "        inputs['src'] = inputs['src'].map(lambda x: torch.tensor(list(chain.from_iterable([self.tokenizer.encode(x[i], max_length = int(512 / len(x)),  add_special_tokens=True) for i in range(len(x))]))))\n",
    "        inputs['clss'] = inputs.src.map(lambda x : torch.cat([torch.where(x == 2)[0], torch.tensor([len(x)])]))\n",
    "        inputs['segs'] = inputs.clss.map(lambda x : torch.tensor(list(chain.from_iterable([[0] * (x[i+1] - x[i]) if i % 2 == 0 else [1] * (x[i+1] - x[i]) for i, val in enumerate(x[:-1])]))))\n",
    "        inputs['clss'] = inputs.clss.map(lambda x : x[:-1])\n",
    "\n",
    "        ##Padding\n",
    "        max_encoding_len = max(inputs.src.map(lambda x: len(x)))\n",
    "        max_label_len = max(inputs.clss.map(lambda x: len(x)))\n",
    "        inputs['src'] = self.pad(inputs.src, 0, max_encoding_len)\n",
    "        inputs['segs'] = self.pad(inputs.segs, 0, max_encoding_len)\n",
    "        inputs['clss'] = self.pad(inputs.clss, -1, max_label_len)\n",
    "        inputs['mask'] = inputs.src.map(lambda x: ~ (x == 0))\n",
    "        inputs['mask_clss'] = inputs.clss.map(lambda x: ~ (x == -1))\n",
    "\n",
    "        #Binarize label {Extracted sentence : 1, Not Extracted sentence : 0}\n",
    "        labels = labels['trg'].map(lambda  x: torch.tensor([1 if i in x else 0 for i in range(max_label_len)]))\n",
    "\n",
    "        return inputs, labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return [self.inputs[index][i] for i in range(5)], self.labels[index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading train dataset..\n",
      "Loading val dataset..\n"
     ]
    }
   ],
   "source": [
    "# Load dataset & dataloader\n",
    "train_dataset = CustomDataset(data_dir=DATA_DIR, mode='train')\n",
    "validation_dataset = CustomDataset(data_dir=DATA_DIR, mode='val')\n",
    "\n",
    "train_dataloader = DataLoader(dataset=train_dataset, batch_size=TRAIN_BATCH_SIZE, shuffle=True)\n",
    "validation_dataloader = DataLoader(dataset=validation_dataset, batch_size=EVAL_BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델설계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "EPOCHS = 10 \n",
    "LEARNING_RATE = 0.005\n",
    "WEIGHT_DECAY = 0.00001\n",
    "NUM_WORKERS = 0\n",
    "EARLY_STOPPING_PATIENCE = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 한국어 자연어 처리의 pretrained model인 KcELECTRA 깃헙 [https://github.com/Beomi/KcELECTRA] 참고\n",
    "- !주의! 모델이 무거우니 사용하는 파라미터 개수와 개발 환경 등을 고려하여 인코더 등을 선택하세요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import transformers\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "class Summarizer(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        super(Summarizer, self).__init__()\n",
    "        self.encoder = transformers.BertModel.from_pretrained(\"beomi/KcELECTRA-base\")\n",
    "        self.fc = nn.Linear(768, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "\n",
    "    def forward(self, x, segs, clss, mask, mask_clss, sentence_range=None):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        top_vec = self.encoder(input_ids = x.long(), attention_mask = mask.float(),  token_type_ids = segs.long()).last_hidden_state\n",
    "        sents_vec = top_vec[torch.arange(top_vec.size(0)).unsqueeze(1), clss.long()]\n",
    "        sents_vec = sents_vec * mask_clss[:, :, None].float()\n",
    "        h = self.fc(sents_vec).squeeze(-1)\n",
    "        sent_scores = self.sigmoid(h) * mask_clss.float()\n",
    "        return sent_scores\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
      "Some weights of the model checkpoint at beomi/KcELECTRA-base were not used when initializing BertModel: ['electra.encoder.layer.5.attention.self.key.bias', 'electra.encoder.layer.3.attention.output.LayerNorm.bias', 'electra.encoder.layer.1.attention.self.value.weight', 'electra.encoder.layer.9.output.dense.weight', 'electra.encoder.layer.3.attention.self.value.weight', 'electra.encoder.layer.5.output.dense.weight', 'electra.encoder.layer.5.attention.output.LayerNorm.weight', 'electra.encoder.layer.8.attention.self.value.bias', 'electra.encoder.layer.9.attention.output.dense.weight', 'electra.encoder.layer.3.output.dense.weight', 'electra.encoder.layer.1.attention.self.query.bias', 'electra.encoder.layer.7.output.LayerNorm.bias', 'electra.encoder.layer.9.output.LayerNorm.bias', 'electra.encoder.layer.11.attention.output.dense.weight', 'electra.encoder.layer.3.output.dense.bias', 'electra.encoder.layer.11.attention.self.key.weight', 'electra.encoder.layer.8.output.LayerNorm.bias', 'electra.encoder.layer.6.attention.output.LayerNorm.weight', 'electra.encoder.layer.1.attention.output.LayerNorm.bias', 'electra.encoder.layer.1.intermediate.dense.weight', 'electra.encoder.layer.0.output.LayerNorm.bias', 'electra.encoder.layer.4.attention.self.value.weight', 'electra.encoder.layer.0.output.dense.bias', 'electra.encoder.layer.0.output.LayerNorm.weight', 'electra.encoder.layer.9.intermediate.dense.bias', 'electra.encoder.layer.11.attention.self.value.weight', 'electra.encoder.layer.10.attention.self.query.weight', 'electra.encoder.layer.4.attention.output.dense.bias', 'electra.encoder.layer.3.output.LayerNorm.bias', 'electra.encoder.layer.11.intermediate.dense.bias', 'electra.encoder.layer.11.intermediate.dense.weight', 'electra.encoder.layer.6.intermediate.dense.bias', 'electra.encoder.layer.11.output.LayerNorm.bias', 'electra.encoder.layer.2.attention.output.LayerNorm.bias', 'electra.encoder.layer.10.output.dense.weight', 'electra.encoder.layer.8.attention.self.key.weight', 'electra.encoder.layer.3.intermediate.dense.bias', 'electra.encoder.layer.9.attention.output.dense.bias', 'discriminator_predictions.dense_prediction.bias', 'electra.encoder.layer.6.output.dense.bias', 'electra.encoder.layer.7.output.LayerNorm.weight', 'electra.encoder.layer.9.attention.self.query.bias', 'electra.encoder.layer.7.attention.self.query.weight', 'electra.encoder.layer.0.attention.self.key.bias', 'electra.encoder.layer.8.attention.output.dense.weight', 'electra.encoder.layer.0.attention.self.key.weight', 'electra.encoder.layer.4.intermediate.dense.weight', 'electra.encoder.layer.0.attention.output.LayerNorm.weight', 'electra.encoder.layer.1.output.LayerNorm.bias', 'electra.encoder.layer.3.attention.self.key.bias', 'electra.encoder.layer.6.attention.self.query.bias', 'electra.encoder.layer.7.attention.self.value.bias', 'electra.encoder.layer.4.attention.output.LayerNorm.weight', 'electra.encoder.layer.5.attention.self.value.weight', 'electra.encoder.layer.7.attention.output.dense.bias', 'electra.encoder.layer.4.output.LayerNorm.weight', 'electra.encoder.layer.9.attention.output.LayerNorm.bias', 'electra.encoder.layer.11.attention.output.dense.bias', 'electra.encoder.layer.6.attention.self.query.weight', 'electra.encoder.layer.11.attention.self.key.bias', 'electra.encoder.layer.3.attention.self.query.bias', 'electra.encoder.layer.10.attention.output.LayerNorm.weight', 'electra.encoder.layer.1.attention.self.key.weight', 'electra.encoder.layer.2.attention.self.value.bias', 'electra.encoder.layer.0.attention.output.dense.bias', 'electra.encoder.layer.6.output.dense.weight', 'electra.encoder.layer.2.intermediate.dense.bias', 'electra.encoder.layer.10.attention.self.value.bias', 'electra.encoder.layer.6.attention.self.value.weight', 'electra.encoder.layer.11.attention.self.query.weight', 'electra.encoder.layer.10.attention.output.dense.bias', 'electra.encoder.layer.8.output.LayerNorm.weight', 'electra.encoder.layer.7.attention.output.dense.weight', 'electra.encoder.layer.6.output.LayerNorm.weight', 'discriminator_predictions.dense.weight', 'electra.encoder.layer.10.attention.self.value.weight', 'electra.encoder.layer.11.attention.self.query.bias', 'electra.encoder.layer.2.attention.self.query.weight', 'electra.encoder.layer.5.attention.self.query.bias', 'electra.encoder.layer.1.attention.output.LayerNorm.weight', 'electra.encoder.layer.7.output.dense.weight', 'electra.encoder.layer.1.attention.output.dense.weight', 'electra.encoder.layer.10.intermediate.dense.bias', 'electra.encoder.layer.1.attention.self.value.bias', 'electra.encoder.layer.2.attention.output.LayerNorm.weight', 'electra.encoder.layer.2.intermediate.dense.weight', 'electra.encoder.layer.3.attention.self.value.bias', 'electra.encoder.layer.0.intermediate.dense.bias', 'electra.embeddings.word_embeddings.weight', 'electra.embeddings.LayerNorm.weight', 'electra.encoder.layer.1.attention.self.key.bias', 'electra.encoder.layer.1.intermediate.dense.bias', 'electra.encoder.layer.8.output.dense.weight', 'electra.encoder.layer.6.intermediate.dense.weight', 'electra.encoder.layer.1.output.LayerNorm.weight', 'electra.encoder.layer.5.attention.output.dense.weight', 'electra.encoder.layer.5.output.dense.bias', 'electra.encoder.layer.5.attention.output.dense.bias', 'electra.encoder.layer.1.attention.output.dense.bias', 'electra.encoder.layer.11.output.dense.weight', 'electra.encoder.layer.9.intermediate.dense.weight', 'electra.encoder.layer.0.output.dense.weight', 'electra.encoder.layer.5.output.LayerNorm.bias', 'electra.encoder.layer.8.output.dense.bias', 'electra.encoder.layer.4.output.dense.bias', 'electra.encoder.layer.2.output.dense.weight', 'electra.encoder.layer.7.attention.self.value.weight', 'electra.encoder.layer.9.attention.self.value.bias', 'electra.encoder.layer.4.intermediate.dense.bias', 'electra.encoder.layer.11.output.LayerNorm.weight', 'electra.encoder.layer.8.intermediate.dense.weight', 'electra.encoder.layer.4.attention.self.value.bias', 'electra.encoder.layer.3.attention.output.LayerNorm.weight', 'electra.encoder.layer.8.attention.output.LayerNorm.bias', 'electra.encoder.layer.9.attention.output.LayerNorm.weight', 'electra.encoder.layer.7.output.dense.bias', 'electra.encoder.layer.6.attention.self.key.bias', 'electra.encoder.layer.2.attention.output.dense.weight', 'electra.encoder.layer.4.attention.output.dense.weight', 'electra.encoder.layer.8.attention.self.query.bias', 'electra.encoder.layer.2.output.dense.bias', 'electra.encoder.layer.7.attention.output.LayerNorm.weight', 'electra.encoder.layer.3.attention.output.dense.bias', 'electra.encoder.layer.10.intermediate.dense.weight', 'electra.encoder.layer.9.attention.self.key.bias', 'electra.encoder.layer.5.attention.self.query.weight', 'electra.encoder.layer.9.attention.self.value.weight', 'electra.encoder.layer.10.attention.self.key.bias', 'electra.encoder.layer.10.attention.self.key.weight', 'electra.encoder.layer.7.intermediate.dense.weight', 'electra.encoder.layer.10.attention.output.dense.weight', 'electra.encoder.layer.2.attention.self.key.weight', 'electra.embeddings.LayerNorm.bias', 'electra.encoder.layer.9.output.dense.bias', 'electra.encoder.layer.1.output.dense.weight', 'electra.encoder.layer.8.attention.self.key.bias', 'electra.encoder.layer.10.attention.output.LayerNorm.bias', 'discriminator_predictions.dense.bias', 'electra.encoder.layer.11.attention.self.value.bias', 'electra.encoder.layer.0.attention.self.query.weight', 'electra.encoder.layer.4.output.dense.weight', 'electra.encoder.layer.11.attention.output.LayerNorm.bias', 'electra.encoder.layer.7.intermediate.dense.bias', 'electra.encoder.layer.10.output.dense.bias', 'electra.encoder.layer.5.attention.self.value.bias', 'electra.encoder.layer.9.attention.self.key.weight', 'electra.encoder.layer.9.attention.self.query.weight', 'electra.encoder.layer.6.attention.output.LayerNorm.bias', 'electra.encoder.layer.11.output.dense.bias', 'electra.encoder.layer.5.intermediate.dense.weight', 'electra.encoder.layer.1.output.dense.bias', 'electra.encoder.layer.3.attention.output.dense.weight', 'electra.encoder.layer.3.attention.self.key.weight', 'electra.encoder.layer.5.output.LayerNorm.weight', 'discriminator_predictions.dense_prediction.weight', 'electra.encoder.layer.10.output.LayerNorm.weight', 'electra.encoder.layer.2.attention.self.query.bias', 'electra.embeddings.token_type_embeddings.weight', 'electra.encoder.layer.1.attention.self.query.weight', 'electra.encoder.layer.4.attention.self.key.weight', 'electra.encoder.layer.4.attention.self.query.bias', 'electra.encoder.layer.3.attention.self.query.weight', 'electra.encoder.layer.4.attention.output.LayerNorm.bias', 'electra.encoder.layer.2.attention.output.dense.bias', 'electra.encoder.layer.9.output.LayerNorm.weight', 'electra.encoder.layer.3.intermediate.dense.weight', 'electra.encoder.layer.5.intermediate.dense.bias', 'electra.encoder.layer.7.attention.self.key.weight', 'electra.encoder.layer.10.attention.self.query.bias', 'electra.encoder.layer.7.attention.output.LayerNorm.bias', 'electra.encoder.layer.11.attention.output.LayerNorm.weight', 'electra.encoder.layer.4.attention.self.key.bias', 'electra.encoder.layer.4.attention.self.query.weight', 'electra.encoder.layer.3.output.LayerNorm.weight', 'electra.encoder.layer.6.attention.self.value.bias', 'electra.encoder.layer.8.attention.output.LayerNorm.weight', 'electra.encoder.layer.6.output.LayerNorm.bias', 'electra.encoder.layer.5.attention.self.key.weight', 'electra.encoder.layer.0.intermediate.dense.weight', 'electra.encoder.layer.2.output.LayerNorm.weight', 'electra.encoder.layer.8.intermediate.dense.bias', 'electra.encoder.layer.6.attention.output.dense.bias', 'electra.embeddings.position_embeddings.weight', 'electra.encoder.layer.0.attention.self.query.bias', 'electra.encoder.layer.0.attention.self.value.weight', 'electra.encoder.layer.7.attention.self.key.bias', 'electra.encoder.layer.2.attention.self.key.bias', 'electra.encoder.layer.0.attention.self.value.bias', 'electra.encoder.layer.7.attention.self.query.bias', 'electra.encoder.layer.8.attention.output.dense.bias', 'electra.embeddings.position_ids', 'electra.encoder.layer.6.attention.output.dense.weight', 'electra.encoder.layer.10.output.LayerNorm.bias', 'electra.encoder.layer.0.attention.output.LayerNorm.bias', 'electra.encoder.layer.2.attention.self.value.weight', 'electra.encoder.layer.0.attention.output.dense.weight', 'electra.encoder.layer.6.attention.self.key.weight', 'electra.encoder.layer.2.output.LayerNorm.bias', 'electra.encoder.layer.4.output.LayerNorm.bias', 'electra.encoder.layer.5.attention.output.LayerNorm.bias', 'electra.encoder.layer.8.attention.self.query.weight', 'electra.encoder.layer.8.attention.self.value.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertModel were not initialized from the model checkpoint at beomi/KcELECTRA-base and are newly initialized: ['encoder.layer.8.attention.output.LayerNorm.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.8.output.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.output.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.6.output.dense.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.7.output.dense.bias', 'embeddings.token_type_embeddings.weight', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.2.output.dense.bias', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.intermediate.dense.weight', 'embeddings.position_embeddings.weight', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.11.output.dense.weight', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.9.output.dense.bias', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.4.output.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.output.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.11.attention.output.dense.weight', 'embeddings.LayerNorm.bias', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.1.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.8.attention.self.query.bias', 'pooler.dense.bias', 'encoder.layer.0.output.dense.bias', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.9.output.dense.weight', 'pooler.dense.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.5.output.dense.bias', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.3.output.dense.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.7.attention.self.value.bias', 'embeddings.LayerNorm.weight', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.10.output.dense.weight', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.4.output.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = Summarizer().to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Hitrate(y_true, y_pred):\n",
    "    \"\"\" Metric 함수 반환하는 함수\n",
    "\n",
    "    Returns:\n",
    "        metric_fn (Callable)\n",
    "    \"\"\"\n",
    "    hitrate = np.array([len(list(set(ans).intersection(y_true[i])))/3 for i, ans in enumerate(y_pred)])\n",
    "    score = np.mean(hitrate)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set optimizer, scheduler, loss function, metric function\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "scheduler = optim.lr_scheduler.OneCycleLR(optimizer=optimizer, pct_start=0.1, div_factor=1e5, max_lr=0.01, epochs=EPOCHS, steps_per_epoch=len(train_dataloader))\n",
    "loss_fn = torch.nn.BCELoss(reduction='none')\n",
    "\n",
    "# Set metrics\n",
    "metric_fn = Hitrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "class LossEarlyStopper():\n",
    "    \"\"\"Early stopper\n",
    "    \n",
    "    Attributes:\n",
    "        patience (int): loss가 줄어들지 않아도 학습할 epoch 수\n",
    "        verbose (bool): 로그 출력 여부, True 일 때 로그 출력\n",
    "        patience_counter (int): loss 가 줄어들지 않을 때 마다 1씩 증가\n",
    "        min_loss (float): 최소 loss\n",
    "        stop (bool): True 일 때 학습 중단\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, patience: int, verbose: bool, logger:logging.RootLogger=None)-> None:\n",
    "        \"\"\" 초기화\n",
    "\n",
    "        Args:\n",
    "            patience (int): loss가 줄어들지 않아도 학습할 epoch 수\n",
    "            weight_path (str): weight 저장경로\n",
    "            verbose (bool): 로그 출력 여부, True 일 때 로그 출력\n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "\n",
    "        self.patience_counter = 0\n",
    "        self.min_loss = np.Inf\n",
    "        self.logger = logger\n",
    "        self.stop = False\n",
    "\n",
    "    def check_early_stopping(self, loss: float)-> None:\n",
    "        \"\"\"Early stopping 여부 판단\n",
    "\n",
    "        Args:\n",
    "            loss (float):\n",
    "\n",
    "        Examples:\n",
    "            \n",
    "        Note:\n",
    "            \n",
    "        \"\"\"  \n",
    "\n",
    "        if self.min_loss == np.Inf:\n",
    "            self.min_loss = loss\n",
    "            # self.save_checkpoint(loss=loss, model=model)\n",
    "\n",
    "        elif loss > self.min_loss:\n",
    "            self.patience_counter += 1\n",
    "            msg = f\"Early stopper, Early stopping counter {self.patience_counter}/{self.patience}\"\n",
    "\n",
    "            if self.patience_counter == self.patience:\n",
    "                self.stop = True\n",
    "\n",
    "            if self.verbose:\n",
    "                self.logger.info(msg) if self.logger else print(msg)\n",
    "                \n",
    "        elif loss <= self.min_loss:\n",
    "            self.save_model = True\n",
    "            msg = f\"Early stopper, Validation loss decreased {self.min_loss} -> {loss}\"\n",
    "            self.min_loss = loss\n",
    "            # self.save_checkpoint(loss=loss, model=model)\n",
    "\n",
    "            if self.verbose:\n",
    "                self.logger.info(msg) if self.logger else print(msg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer():\n",
    "    \"\"\" Trainer\n",
    "        epoch에 대한 학습 및 검증 절차 정의\n",
    "    \n",
    "    Attributes:\n",
    "        model (`model`)\n",
    "        device (str)\n",
    "        loss_fn (Callable)\n",
    "        metric_fn (Callable)\n",
    "        optimizer (`optimizer`)\n",
    "        scheduler (`scheduler`)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, model, device, loss_fn, metric_fn, optimizer=None, scheduler=None, logger=None):\n",
    "        \"\"\" 초기화\n",
    "        \"\"\"\n",
    "        self.model = model\n",
    "        self.device = device\n",
    "        self.loss_fn = loss_fn\n",
    "        self.metric_fn = metric_fn\n",
    "        self.optimizer = optimizer\n",
    "        self.scheduler = scheduler\n",
    "        self.logger = logger\n",
    "\n",
    "    def train_epoch(self, dataloader, epoch_index):\n",
    "        \"\"\" 한 epoch에서 수행되는 학습 절차\n",
    "\n",
    "        Args:\n",
    "            dataloader (`dataloader`)\n",
    "            epoch_index (int)\n",
    "        \"\"\"\n",
    "        self.model.train()\n",
    "        self.train_total_loss = 0\n",
    "        pred_lst = []\n",
    "        target_lst = []\n",
    "        for batch_index, (data, target) in enumerate(dataloader):\n",
    "            self.optimizer.zero_grad()\n",
    "            src = data[0].to(self.device)\n",
    "            clss = data[1].to(self.device)\n",
    "            segs = data[2].to(self.device)\n",
    "            mask = data[3].to(self.device)\n",
    "            mask_clss = data[4].to(self.device)\n",
    "            target = target.float().to(self.device)\n",
    "            sent_score = self.model(src, segs, clss, mask, mask_clss)\n",
    "            loss = self.loss_fn(sent_score, target)\n",
    "            loss = (loss * mask_clss.float()).sum()\n",
    "            self.train_total_loss += loss\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            self.scheduler.step()\n",
    "            pred_lst.extend(torch.topk(sent_score, 3, axis=1).indices.tolist())\n",
    "            try:\n",
    "                target_lst.extend(torch.where(target==1)[1].reshape(-1,3).tolist())\n",
    "            except:\n",
    "                print(target)\n",
    "                sys.exit()\n",
    "                \n",
    "        self.train_mean_loss = self.train_total_loss / len(dataloader)\n",
    "        self.train_score = self.metric_fn(y_true=target_lst, y_pred=pred_lst)\n",
    "        msg = f'Epoch {epoch_index}, Train, loss: {self.train_mean_loss}, Score: {self.train_score}'\n",
    "        print(msg)\n",
    "\n",
    "    def validate_epoch(self, dataloader, epoch_index):\n",
    "        \"\"\" 한 epoch에서 수행되는 검증 절차\n",
    "\n",
    "        Args:\n",
    "            dataloader (`dataloader`)\n",
    "            epoch_index (int)\n",
    "        \"\"\"\n",
    "        self.model.eval()\n",
    "        self.val_total_loss = 0\n",
    "        pred_lst = []\n",
    "        target_lst = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch_index, (data, target) in enumerate(dataloader):\n",
    "                src = data[0].to(self.device)\n",
    "                clss = data[1].to(self.device)\n",
    "                segs = data[2].to(self.device)\n",
    "                mask = data[3].to(self.device)\n",
    "                mask_clss = data[4].to(self.device)\n",
    "                target = target.float().to(self.device)\n",
    "                sent_score = self.model(src, segs, clss, mask, mask_clss)\n",
    "                loss = self.loss_fn(sent_score, target)\n",
    "                loss = (loss * mask_clss.float()).sum()\n",
    "                self.val_total_loss += loss\n",
    "                pred_lst.extend(torch.topk(sent_score, 3, axis=1).indices.tolist())\n",
    "                target_lst.extend(torch.where(target==1)[1].reshape(-1,3).tolist())\n",
    "            self.val_mean_loss = self.val_total_loss / len(dataloader)\n",
    "            self.validation_score = self.metric_fn(y_true=target_lst, y_pred=pred_lst)\n",
    "            msg = f'Epoch {epoch_index}, Validation, loss: {self.val_mean_loss}, Score: {self.validation_score}'\n",
    "            print(msg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set trainer\n",
    "trainer = Trainer(model, DEVICE, loss_fn, metric_fn, optimizer, scheduler)\n",
    "\n",
    "# Set earlystopper\n",
    "early_stopper = LossEarlyStopper(patience=EARLY_STOPPING_PATIENCE, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache() # PyTorch thing\n",
    "\n",
    "with torch.no_grad():\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Train, loss: 35.507381439208984, Score: 0.4337418111753372\n",
      "Epoch 0, Validation, loss: 23.548355102539062, Score: 0.39439356092145433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10% 1/10 [1:06:43<10:00:28, 4003.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train, loss: 35.89322280883789, Score: 0.4284393063583815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20% 2/10 [1:53:08<7:18:13, 3286.67s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Validation, loss: 23.39459800720215, Score: 0.3850957535387177\n",
      "Early stopper, Validation loss decreased 23.548355102539062 -> 23.39459800720215\n",
      "Epoch 2, Train, loss: 35.91456985473633, Score: 0.4300269749518304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30% 3/10 [2:41:20<6:02:25, 3106.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Validation, loss: 23.414875030517578, Score: 0.3850957535387177\n",
      "Early stopper, Early stopping counter 1/20\n",
      "Epoch 3, Train, loss: 35.87749099731445, Score: 0.4293333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40% 4/10 [3:25:46<4:53:14, 2932.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Validation, loss: 23.392942428588867, Score: 0.3850957535387177\n",
      "Early stopper, Validation loss decreased 23.39459800720215 -> 23.392942428588867\n",
      "Epoch 4, Train, loss: 35.92258834838867, Score: 0.4280693641618497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50% 5/10 [4:07:12<3:50:57, 2771.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Validation, loss: 23.436002731323242, Score: 0.3850957535387177\n",
      "Early stopper, Early stopping counter 2/20\n",
      "Epoch 5, Train, loss: 35.82049560546875, Score: 0.43173795761079004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60% 6/10 [4:47:08<2:56:15, 2643.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Validation, loss: 23.399343490600586, Score: 0.3850957535387177\n",
      "Early stopper, Early stopping counter 3/20\n",
      "Epoch 6, Train, loss: 35.79829788208008, Score: 0.4303969171483622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70% 7/10 [5:26:05<2:07:11, 2543.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Validation, loss: 23.393136978149414, Score: 0.3850957535387177\n",
      "Early stopper, Early stopping counter 4/20\n",
      "Epoch 7, Train, loss: 35.77375793457031, Score: 0.4307822736030828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80% 8/10 [6:04:35<1:22:18, 2469.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Validation, loss: 23.3988094329834, Score: 0.3850957535387177\n",
      "Early stopper, Early stopping counter 5/20\n",
      "Epoch 8, Train, loss: 35.76350021362305, Score: 0.4292100192678228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90% 9/10 [6:42:48<40:14, 2414.11s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Validation, loss: 23.402734756469727, Score: 0.3850957535387177\n",
      "Early stopper, Early stopping counter 6/20\n",
      "Epoch 9, Train, loss: 35.76081848144531, Score: 0.42987283236994217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 10/10 [7:43:30<00:00, 2781.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Validation, loss: 23.400680541992188, Score: 0.3850957535387177\n",
      "Early stopper, Early stopping counter 7/20\n",
      "train finished, best.pt saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# TRAIN\n",
    "from tqdm import tqdm\n",
    "\n",
    "start = time.time()\n",
    "criterion = 0\n",
    "\n",
    "for epoch_index in tqdm(range(EPOCHS)):\n",
    "    \n",
    "    trainer.train_epoch(train_dataloader, epoch_index=epoch_index)\n",
    "    trainer.validate_epoch(validation_dataloader, epoch_index=epoch_index)\n",
    "   \n",
    "    # early_stopping check\n",
    "    early_stopper.check_early_stopping(loss=trainer.val_mean_loss)\n",
    "\n",
    "    if early_stopper.stop:\n",
    "        print('Early stopped')\n",
    "        break\n",
    "\n",
    "    if trainer.validation_score > criterion:\n",
    "        criterion = trainer.validation_score\n",
    "        check_point = {\n",
    "            'model' : model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "            'scheduler': scheduler.state_dict()\n",
    "        }\n",
    "        \n",
    "        torch.save(check_point, os.path.join(MODEL_DIR, 'best.pt'))\n",
    "        \n",
    "        \n",
    "print(\"train finished, best.pt saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 추론\n",
    "테스트 데이터의 타겟 변수를 `sample_submission.csv` 양식에 맞춰 저장하고, 해당 제출파일을 Inclass에 제출하시면 점수를 확인할 수 있습니다.\n",
    "\n",
    "여러분의 모델의 추론 결과로 나온 문서 당 세 개의 요약 인덱스에 해당하는 \"idx_#\"을 1로 채워 제출 파일을 만듭니다(현재는 아래 보시는 바와 같이 모두 0으로 채워져 있습니다). ID 값을 기준으로 채점을 진행하는 점 유의해주시기 바랍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>idx_0</th>\n",
       "      <th>idx_1</th>\n",
       "      <th>idx_2</th>\n",
       "      <th>idx_3</th>\n",
       "      <th>idx_4</th>\n",
       "      <th>idx_5</th>\n",
       "      <th>idx_6</th>\n",
       "      <th>idx_7</th>\n",
       "      <th>idx_8</th>\n",
       "      <th>...</th>\n",
       "      <th>idx_39</th>\n",
       "      <th>idx_40</th>\n",
       "      <th>idx_41</th>\n",
       "      <th>idx_42</th>\n",
       "      <th>idx_43</th>\n",
       "      <th>idx_44</th>\n",
       "      <th>idx_45</th>\n",
       "      <th>idx_46</th>\n",
       "      <th>idx_47</th>\n",
       "      <th>idx_48</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>79095</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>204506</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>142079</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>110816</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>207249</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ID  idx_0  idx_1  idx_2  idx_3  idx_4  idx_5  idx_6  idx_7  idx_8  ...  \\\n",
       "0   79095      0      0      0      0      0      0      0      0      0  ...   \n",
       "1  204506      0      0      0      0      0      0      0      0      0  ...   \n",
       "2  142079      0      0      0      0      0      0      0      0      0  ...   \n",
       "3  110816      0      0      0      0      0      0      0      0      0  ...   \n",
       "4  207249      0      0      0      0      0      0      0      0      0  ...   \n",
       "\n",
       "   idx_39  idx_40  idx_41  idx_42  idx_43  idx_44  idx_45  idx_46  idx_47  \\\n",
       "0       0       0       0       0       0       0       0       0       0   \n",
       "1       0       0       0       0       0       0       0       0       0   \n",
       "2       0       0       0       0       0       0       0       0       0   \n",
       "3       0       0       0       0       0       0       0       0       0   \n",
       "4       0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   idx_48  \n",
       "0       0  \n",
       "1       0  \n",
       "2       0  \n",
       "3       0  \n",
       "4       0  \n",
       "\n",
       "[5 rows x 50 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit = pd.read_csv(os.path.join(DATA_DIR,'sample_submission.csv'))\n",
    "submit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트 데이터셋 클래스 정의\n",
    "\n",
    "class TestDataset(Dataset):\n",
    "    \"\"\" CustomDataset과 비슷한 구조이지만 레이블이 주어지지 않음을 염두 \"\"\"\n",
    "\n",
    "    def __init__(self, data_dir, mode):\n",
    "        self.data_dir = data_dir\n",
    "        self.mode = mode\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(\"beomi/KcELECTRA-base\")\n",
    "        self.inputs = self.data_loader()\n",
    "\n",
    "    def data_loader(self):\n",
    "        print('Loading ' + self.mode + ' dataset..')\n",
    "        if os.path.isfile(os.path.join(self.data_dir, self.mode+'_X.pt')):\n",
    "            # torch tensor 불러오기\n",
    "            inputs = torch.load(os.path.join(self.data_dir, self.mode + '_X.pt'))\n",
    "        else:\n",
    "            # json 파일 불러오기\n",
    "            file_path = os.path.join(self.data_dir, self.mode + '.json')\n",
    "            df = pd.read_json(file_path, orient='records', encoding='utf-8-sig')\n",
    "            inputs = pd.DataFrame(columns=['src'])\n",
    "            inputs['src'] =  df['article_original']\n",
    "      \n",
    "            # 전처리\n",
    "            inputs = self.preprocessing(inputs)\n",
    "            \n",
    "            # 다음부터는 전처리 과정을 반복하지 않기 위해 tensor 저장\n",
    "            torch.save(inputs ,os.path.join(self.data_dir, self.mode + '_X.pt'))\n",
    "\n",
    "        inputs = inputs.values\n",
    "\n",
    "        return inputs\n",
    "\n",
    "    def pad(self, data, pad_id, max_len):\n",
    "        padded_data = data.map(lambda x : torch.cat([x, torch.tensor([pad_id] * (max_len - len(x)))]))\n",
    "        return padded_data\n",
    "\n",
    "    def preprocessing(self, inputs):\n",
    "        print('Preprocessing ' + self.mode + ' dataset..')\n",
    "        \n",
    "        #Encoding original text\n",
    "        inputs['src'] = inputs['src'].map(lambda x: torch.tensor(list(chain.from_iterable([self.tokenizer.encode(x[i], max_length = int(512 / len(x)),  add_special_tokens=True) for i in range(len(x))]))))\n",
    "        inputs['clss'] = inputs.src.map(lambda x : torch.cat([torch.where(x == 2)[0], torch.tensor([len(x)])]))\n",
    "        inputs['segs'] = inputs.clss.map(lambda x : torch.tensor(list(chain.from_iterable([[0] * (x[i+1] - x[i]) if i % 2 == 0 else [1] * (x[i+1] - x[i]) for i, val in enumerate(x[:-1])]))))\n",
    "        inputs['clss'] = inputs.clss.map(lambda x : x[:-1])\n",
    "\n",
    "        ##Padding\n",
    "        max_encoding_len = max(inputs.src.map(lambda x: len(x)))\n",
    "        max_label_len = max(inputs.clss.map(lambda x: len(x)))\n",
    "        inputs['src'] = self.pad(inputs.src, 0, max_encoding_len)\n",
    "        inputs['segs'] = self.pad(inputs.segs, 0, max_encoding_len)\n",
    "        inputs['clss'] = self.pad(inputs.clss, -1, max_label_len)\n",
    "        inputs['mask'] = inputs.src.map(lambda x: ~ (x == 0))\n",
    "        inputs['mask_clss'] = inputs.clss.map(lambda x: ~ (x == -1))\n",
    "     \n",
    "        return inputs\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return [self.inputs[index][i] for i in range(5)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading test dataset..\n"
     ]
    }
   ],
   "source": [
    "# 테스트 데이터 로드\n",
    "test_dataset = TestDataset(data_dir=DATA_DIR, mode = 'test')\n",
    "test_dataloader = DataLoader(dataset=test_dataset, batch_size=TRAIN_BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
      "Some weights of the model checkpoint at beomi/KcELECTRA-base were not used when initializing BertModel: ['electra.encoder.layer.5.attention.self.key.bias', 'electra.encoder.layer.3.attention.output.LayerNorm.bias', 'electra.encoder.layer.1.attention.self.value.weight', 'electra.encoder.layer.9.output.dense.weight', 'electra.encoder.layer.3.attention.self.value.weight', 'electra.encoder.layer.5.output.dense.weight', 'electra.encoder.layer.5.attention.output.LayerNorm.weight', 'electra.encoder.layer.8.attention.self.value.bias', 'electra.encoder.layer.9.attention.output.dense.weight', 'electra.encoder.layer.3.output.dense.weight', 'electra.encoder.layer.1.attention.self.query.bias', 'electra.encoder.layer.7.output.LayerNorm.bias', 'electra.encoder.layer.9.output.LayerNorm.bias', 'electra.encoder.layer.11.attention.output.dense.weight', 'electra.encoder.layer.3.output.dense.bias', 'electra.encoder.layer.11.attention.self.key.weight', 'electra.encoder.layer.8.output.LayerNorm.bias', 'electra.encoder.layer.6.attention.output.LayerNorm.weight', 'electra.encoder.layer.1.attention.output.LayerNorm.bias', 'electra.encoder.layer.1.intermediate.dense.weight', 'electra.encoder.layer.0.output.LayerNorm.bias', 'electra.encoder.layer.4.attention.self.value.weight', 'electra.encoder.layer.0.output.dense.bias', 'electra.encoder.layer.0.output.LayerNorm.weight', 'electra.encoder.layer.9.intermediate.dense.bias', 'electra.encoder.layer.11.attention.self.value.weight', 'electra.encoder.layer.10.attention.self.query.weight', 'electra.encoder.layer.4.attention.output.dense.bias', 'electra.encoder.layer.3.output.LayerNorm.bias', 'electra.encoder.layer.11.intermediate.dense.bias', 'electra.encoder.layer.11.intermediate.dense.weight', 'electra.encoder.layer.6.intermediate.dense.bias', 'electra.encoder.layer.11.output.LayerNorm.bias', 'electra.encoder.layer.2.attention.output.LayerNorm.bias', 'electra.encoder.layer.10.output.dense.weight', 'electra.encoder.layer.8.attention.self.key.weight', 'electra.encoder.layer.3.intermediate.dense.bias', 'electra.encoder.layer.9.attention.output.dense.bias', 'discriminator_predictions.dense_prediction.bias', 'electra.encoder.layer.6.output.dense.bias', 'electra.encoder.layer.7.output.LayerNorm.weight', 'electra.encoder.layer.9.attention.self.query.bias', 'electra.encoder.layer.7.attention.self.query.weight', 'electra.encoder.layer.0.attention.self.key.bias', 'electra.encoder.layer.8.attention.output.dense.weight', 'electra.encoder.layer.0.attention.self.key.weight', 'electra.encoder.layer.4.intermediate.dense.weight', 'electra.encoder.layer.0.attention.output.LayerNorm.weight', 'electra.encoder.layer.1.output.LayerNorm.bias', 'electra.encoder.layer.3.attention.self.key.bias', 'electra.encoder.layer.6.attention.self.query.bias', 'electra.encoder.layer.7.attention.self.value.bias', 'electra.encoder.layer.4.attention.output.LayerNorm.weight', 'electra.encoder.layer.5.attention.self.value.weight', 'electra.encoder.layer.7.attention.output.dense.bias', 'electra.encoder.layer.4.output.LayerNorm.weight', 'electra.encoder.layer.9.attention.output.LayerNorm.bias', 'electra.encoder.layer.11.attention.output.dense.bias', 'electra.encoder.layer.6.attention.self.query.weight', 'electra.encoder.layer.11.attention.self.key.bias', 'electra.encoder.layer.3.attention.self.query.bias', 'electra.encoder.layer.10.attention.output.LayerNorm.weight', 'electra.encoder.layer.1.attention.self.key.weight', 'electra.encoder.layer.2.attention.self.value.bias', 'electra.encoder.layer.0.attention.output.dense.bias', 'electra.encoder.layer.6.output.dense.weight', 'electra.encoder.layer.2.intermediate.dense.bias', 'electra.encoder.layer.10.attention.self.value.bias', 'electra.encoder.layer.6.attention.self.value.weight', 'electra.encoder.layer.11.attention.self.query.weight', 'electra.encoder.layer.10.attention.output.dense.bias', 'electra.encoder.layer.8.output.LayerNorm.weight', 'electra.encoder.layer.7.attention.output.dense.weight', 'electra.encoder.layer.6.output.LayerNorm.weight', 'discriminator_predictions.dense.weight', 'electra.encoder.layer.10.attention.self.value.weight', 'electra.encoder.layer.11.attention.self.query.bias', 'electra.encoder.layer.2.attention.self.query.weight', 'electra.encoder.layer.5.attention.self.query.bias', 'electra.encoder.layer.1.attention.output.LayerNorm.weight', 'electra.encoder.layer.7.output.dense.weight', 'electra.encoder.layer.1.attention.output.dense.weight', 'electra.encoder.layer.10.intermediate.dense.bias', 'electra.encoder.layer.1.attention.self.value.bias', 'electra.encoder.layer.2.attention.output.LayerNorm.weight', 'electra.encoder.layer.2.intermediate.dense.weight', 'electra.encoder.layer.3.attention.self.value.bias', 'electra.encoder.layer.0.intermediate.dense.bias', 'electra.embeddings.word_embeddings.weight', 'electra.embeddings.LayerNorm.weight', 'electra.encoder.layer.1.attention.self.key.bias', 'electra.encoder.layer.1.intermediate.dense.bias', 'electra.encoder.layer.8.output.dense.weight', 'electra.encoder.layer.6.intermediate.dense.weight', 'electra.encoder.layer.1.output.LayerNorm.weight', 'electra.encoder.layer.5.attention.output.dense.weight', 'electra.encoder.layer.5.output.dense.bias', 'electra.encoder.layer.5.attention.output.dense.bias', 'electra.encoder.layer.1.attention.output.dense.bias', 'electra.encoder.layer.11.output.dense.weight', 'electra.encoder.layer.9.intermediate.dense.weight', 'electra.encoder.layer.0.output.dense.weight', 'electra.encoder.layer.5.output.LayerNorm.bias', 'electra.encoder.layer.8.output.dense.bias', 'electra.encoder.layer.4.output.dense.bias', 'electra.encoder.layer.2.output.dense.weight', 'electra.encoder.layer.7.attention.self.value.weight', 'electra.encoder.layer.9.attention.self.value.bias', 'electra.encoder.layer.4.intermediate.dense.bias', 'electra.encoder.layer.11.output.LayerNorm.weight', 'electra.encoder.layer.8.intermediate.dense.weight', 'electra.encoder.layer.4.attention.self.value.bias', 'electra.encoder.layer.3.attention.output.LayerNorm.weight', 'electra.encoder.layer.8.attention.output.LayerNorm.bias', 'electra.encoder.layer.9.attention.output.LayerNorm.weight', 'electra.encoder.layer.7.output.dense.bias', 'electra.encoder.layer.6.attention.self.key.bias', 'electra.encoder.layer.2.attention.output.dense.weight', 'electra.encoder.layer.4.attention.output.dense.weight', 'electra.encoder.layer.8.attention.self.query.bias', 'electra.encoder.layer.2.output.dense.bias', 'electra.encoder.layer.7.attention.output.LayerNorm.weight', 'electra.encoder.layer.3.attention.output.dense.bias', 'electra.encoder.layer.10.intermediate.dense.weight', 'electra.encoder.layer.9.attention.self.key.bias', 'electra.encoder.layer.5.attention.self.query.weight', 'electra.encoder.layer.9.attention.self.value.weight', 'electra.encoder.layer.10.attention.self.key.bias', 'electra.encoder.layer.10.attention.self.key.weight', 'electra.encoder.layer.7.intermediate.dense.weight', 'electra.encoder.layer.10.attention.output.dense.weight', 'electra.encoder.layer.2.attention.self.key.weight', 'electra.embeddings.LayerNorm.bias', 'electra.encoder.layer.9.output.dense.bias', 'electra.encoder.layer.1.output.dense.weight', 'electra.encoder.layer.8.attention.self.key.bias', 'electra.encoder.layer.10.attention.output.LayerNorm.bias', 'discriminator_predictions.dense.bias', 'electra.encoder.layer.11.attention.self.value.bias', 'electra.encoder.layer.0.attention.self.query.weight', 'electra.encoder.layer.4.output.dense.weight', 'electra.encoder.layer.11.attention.output.LayerNorm.bias', 'electra.encoder.layer.7.intermediate.dense.bias', 'electra.encoder.layer.10.output.dense.bias', 'electra.encoder.layer.5.attention.self.value.bias', 'electra.encoder.layer.9.attention.self.key.weight', 'electra.encoder.layer.9.attention.self.query.weight', 'electra.encoder.layer.6.attention.output.LayerNorm.bias', 'electra.encoder.layer.11.output.dense.bias', 'electra.encoder.layer.5.intermediate.dense.weight', 'electra.encoder.layer.1.output.dense.bias', 'electra.encoder.layer.3.attention.output.dense.weight', 'electra.encoder.layer.3.attention.self.key.weight', 'electra.encoder.layer.5.output.LayerNorm.weight', 'discriminator_predictions.dense_prediction.weight', 'electra.encoder.layer.10.output.LayerNorm.weight', 'electra.encoder.layer.2.attention.self.query.bias', 'electra.embeddings.token_type_embeddings.weight', 'electra.encoder.layer.1.attention.self.query.weight', 'electra.encoder.layer.4.attention.self.key.weight', 'electra.encoder.layer.4.attention.self.query.bias', 'electra.encoder.layer.3.attention.self.query.weight', 'electra.encoder.layer.4.attention.output.LayerNorm.bias', 'electra.encoder.layer.2.attention.output.dense.bias', 'electra.encoder.layer.9.output.LayerNorm.weight', 'electra.encoder.layer.3.intermediate.dense.weight', 'electra.encoder.layer.5.intermediate.dense.bias', 'electra.encoder.layer.7.attention.self.key.weight', 'electra.encoder.layer.10.attention.self.query.bias', 'electra.encoder.layer.7.attention.output.LayerNorm.bias', 'electra.encoder.layer.11.attention.output.LayerNorm.weight', 'electra.encoder.layer.4.attention.self.key.bias', 'electra.encoder.layer.4.attention.self.query.weight', 'electra.encoder.layer.3.output.LayerNorm.weight', 'electra.encoder.layer.6.attention.self.value.bias', 'electra.encoder.layer.8.attention.output.LayerNorm.weight', 'electra.encoder.layer.6.output.LayerNorm.bias', 'electra.encoder.layer.5.attention.self.key.weight', 'electra.encoder.layer.0.intermediate.dense.weight', 'electra.encoder.layer.2.output.LayerNorm.weight', 'electra.encoder.layer.8.intermediate.dense.bias', 'electra.encoder.layer.6.attention.output.dense.bias', 'electra.embeddings.position_embeddings.weight', 'electra.encoder.layer.0.attention.self.query.bias', 'electra.encoder.layer.0.attention.self.value.weight', 'electra.encoder.layer.7.attention.self.key.bias', 'electra.encoder.layer.2.attention.self.key.bias', 'electra.encoder.layer.0.attention.self.value.bias', 'electra.encoder.layer.7.attention.self.query.bias', 'electra.encoder.layer.8.attention.output.dense.bias', 'electra.embeddings.position_ids', 'electra.encoder.layer.6.attention.output.dense.weight', 'electra.encoder.layer.10.output.LayerNorm.bias', 'electra.encoder.layer.0.attention.output.LayerNorm.bias', 'electra.encoder.layer.2.attention.self.value.weight', 'electra.encoder.layer.0.attention.output.dense.weight', 'electra.encoder.layer.6.attention.self.key.weight', 'electra.encoder.layer.2.output.LayerNorm.bias', 'electra.encoder.layer.4.output.LayerNorm.bias', 'electra.encoder.layer.5.attention.output.LayerNorm.bias', 'electra.encoder.layer.8.attention.self.query.weight', 'electra.encoder.layer.8.attention.self.value.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertModel were not initialized from the model checkpoint at beomi/KcELECTRA-base and are newly initialized: ['encoder.layer.8.attention.output.LayerNorm.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.8.output.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.output.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.6.output.dense.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.7.output.dense.bias', 'embeddings.token_type_embeddings.weight', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.2.output.dense.bias', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.intermediate.dense.weight', 'embeddings.position_embeddings.weight', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.11.output.dense.weight', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.9.output.dense.bias', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.4.output.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.output.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.11.attention.output.dense.weight', 'embeddings.LayerNorm.bias', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.1.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.8.attention.self.query.bias', 'pooler.dense.bias', 'encoder.layer.0.output.dense.bias', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.9.output.dense.weight', 'pooler.dense.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.5.output.dense.bias', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.3.output.dense.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.7.attention.self.value.bias', 'embeddings.LayerNorm.weight', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.10.output.dense.weight', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.4.output.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: 0/501 completed\n",
      "Prediction: 150/501 completed\n",
      "Prediction: 300/501 completed\n",
      "Prediction: 450/501 completed\n",
      "Prediction all completed\n"
     ]
    }
   ],
   "source": [
    "\"\"\" 이전에 학습한 모델 weight파일을 불러 추론하려면 아래 주석을 풀고 실행\n",
    "    학습 진행 후 바로 추론하는 경우 학습 과정의 model 사용 (주석 풀지 않고 실행) \"\"\"\n",
    "MODEL_DIR = os.path.join(ROOT_PATH, 'best.pt')\n",
    "model = Summarizer().to(DEVICE)\n",
    "model.load_state_dict(torch.load(MODEL_DIR)['model'])\n",
    "\n",
    "# 추론\n",
    "model.eval()\n",
    "\n",
    "# 추론 결과를 pred 리스트로 저장할 예정\n",
    "pred_lst = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_index, (data) in enumerate(test_dataloader):\n",
    "        src = data[0].to(DEVICE)\n",
    "        clss = data[1].to(DEVICE)\n",
    "        segs = data[2].to(DEVICE)\n",
    "        mask = data[3].to(DEVICE)\n",
    "        mask_clss = data[4].to(DEVICE)\n",
    "        sent_score = model(src, segs, clss, mask, mask_clss)\n",
    "        pred_lst.extend(torch.topk(sent_score, 3, axis=1).indices.tolist())\n",
    "            \n",
    "        # 진행과정 출력\n",
    "        if batch_index % 150 == 0:\n",
    "            print(f'Prediction: {batch_index}/{len(test_dataloader)} completed')\n",
    "    print(\"Prediction all completed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 2, 1], [3, 2, 1], [2, 1, 0], [6, 3, 0], [3, 2, 0]]\n"
     ]
    }
   ],
   "source": [
    "print(pred_lst[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>idx_0</th>\n",
       "      <th>idx_1</th>\n",
       "      <th>idx_2</th>\n",
       "      <th>idx_3</th>\n",
       "      <th>idx_4</th>\n",
       "      <th>idx_5</th>\n",
       "      <th>idx_6</th>\n",
       "      <th>idx_7</th>\n",
       "      <th>idx_8</th>\n",
       "      <th>...</th>\n",
       "      <th>idx_39</th>\n",
       "      <th>idx_40</th>\n",
       "      <th>idx_41</th>\n",
       "      <th>idx_42</th>\n",
       "      <th>idx_43</th>\n",
       "      <th>idx_44</th>\n",
       "      <th>idx_45</th>\n",
       "      <th>idx_46</th>\n",
       "      <th>idx_47</th>\n",
       "      <th>idx_48</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>79095</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>204506</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>142079</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>110816</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>207249</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ID  idx_0  idx_1  idx_2  idx_3  idx_4  idx_5  idx_6  idx_7  idx_8  ...  \\\n",
       "0   79095      2      2      2      0      0      0      0      0      0  ...   \n",
       "1  204506      1      2      2      1      0      0      0      0      0  ...   \n",
       "2  142079      2      2      2      0      0      0      0      0      0  ...   \n",
       "3  110816      2      1      1      1      0      0      1      0      0  ...   \n",
       "4  207249      2      1      2      1      0      0      0      0      0  ...   \n",
       "\n",
       "   idx_39  idx_40  idx_41  idx_42  idx_43  idx_44  idx_45  idx_46  idx_47  \\\n",
       "0       0       0       0       0       0       0       0       0       0   \n",
       "1       0       0       0       0       0       0       0       0       0   \n",
       "2       0       0       0       0       0       0       0       0       0   \n",
       "3       0       0       0       0       0       0       0       0       0   \n",
       "4       0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   idx_48  \n",
       "0       0  \n",
       "1       0  \n",
       "2       0  \n",
       "3       0  \n",
       "4       0  \n",
       "\n",
       "[5 rows x 50 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 제출 파일\n",
    "for i,txt in enumerate(pred_lst):\n",
    "    submit.iloc[i,txt[0]+1] += 1\n",
    "    submit.iloc[i,txt[1]+1] += 1\n",
    "    submit.iloc[i,txt[2]+1] += 1\n",
    "submit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit.to_csv(os.path.join(ROOT_PATH, 'prediction2.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
