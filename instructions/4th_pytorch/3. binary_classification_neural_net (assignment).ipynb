{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.3"},"latex_envs":{"LaTeX_envs_menu_present":true,"autoclose":false,"autocomplete":true,"bibliofile":"biblio.bib","cite_by":"apalike","current_citInitial":1,"eqLabelWithNumbers":true,"eqNumInitial":1,"hotkeys":{"equation":"Ctrl-E","itemize":"Ctrl-I"},"labels_anchors":false,"latex_user_defs":false,"report_style_numbering":false,"user_envs_cfg":false},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{},"toc_section_display":true,"toc_window_display":false},"varInspector":{"cols":{"lenName":16,"lenType":16,"lenVar":40},"kernels_config":{"python":{"delete_cmd_postfix":"","delete_cmd_prefix":"del ","library":"var_list.py","varRefreshCmd":"print(var_dic_list())"},"r":{"delete_cmd_postfix":") ","delete_cmd_prefix":"rm(","library":"var_list.r","varRefreshCmd":"cat(var_dic_list()) "}},"types_to_exclude":["module","function","builtin_function_or_method","instance","_Feature"],"window_display":false},"colab":{"name":"3. binary_classification_neural_net (assignment).ipynb","provenance":[],"collapsed_sections":["-y0MK3h3bPeY","Ah9wBbeibPec"]}},"cells":[{"cell_type":"markdown","metadata":{"id":"tQbVFOyIbPeB"},"source":["## Binary Classification - Titanic: Machine Learning from Disaster\n","\n","https://www.kaggle.com/c/titanic\n","\n","- 유명한 자료인 타이타닉 데이터 셋으로 생존과 사망에 대한 분류 문제를 풀어보도록 하겠습니다."]},{"cell_type":"markdown","metadata":{"id":"RmkGD5QbbPeI"},"source":["![대체 텍스트](../figures2/binary.png)"]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2018-10-28T07:34:29.202719Z","start_time":"2018-10-28T07:34:29.192102Z"},"scrolled":true,"id":"k7QpTypJbPeJ","outputId":"991fb22b-b63b-4a9b-c7c4-8c9857d88254"},"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import numpy as np\n","import random\n","import pandas as pd\n","import matplotlib.pyplot as plt \n","\n","random.seed(1215)\n","torch.manual_seed(1215)"],"execution_count":null,"outputs":[{"data":{"text/plain":["<torch._C.Generator at 0x7fef80049f90>"]},"execution_count":1,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2018-10-28T06:53:30.685976Z","start_time":"2018-10-28T06:53:25.255348Z"},"id":"vcXrQjzYbPeM"},"source":["from torch.utils.data import Dataset\n","from torch.utils.data import DataLoader\n","\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.metrics import accuracy_score\n","from sklearn.model_selection import train_test_split"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"e8pEEQILbPeN"},"source":["# Load Data"]},{"cell_type":"code","metadata":{"id":"PaVrdTsSrVHL"},"source":["from google.colab import files\n","uploaded = files.upload()\n","for fn in uploaded.keys():\n","  print('{name} Uploaded.'.format(name=fn))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2018-10-28T07:48:19.716052Z","start_time":"2018-10-28T07:48:19.695224Z"},"id":"EQb7w0WFbPeO","outputId":"b7c6dd20-6793-4c1f-b555-d64f0b9e04e1"},"source":["import pandas as pd\n","\n","train_data = pd.read_csv(\"./train.csv\")\n","test_data = pd.read_csv(\"./test.csv\")"],"execution_count":null,"outputs":[{"ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: './data/titanic/train.csv'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-7d2dc71a6da4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrain_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./data/titanic/train.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mtest_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./data/titanic/test.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/home/nas1_userD/jinhee/anaconda3/envs/py3.8_torch1.6.0/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    684\u001b[0m     )\n\u001b[1;32m    685\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 686\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/home/nas1_userD/jinhee/anaconda3/envs/py3.8_torch1.6.0/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 452\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/home/nas1_userD/jinhee/anaconda3/envs/py3.8_torch1.6.0/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    934\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 936\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    937\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    938\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/home/nas1_userD/jinhee/anaconda3/envs/py3.8_torch1.6.0/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1166\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1167\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1168\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1169\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1170\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/home/nas1_userD/jinhee/anaconda3/envs/py3.8_torch1.6.0/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1996\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1997\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1998\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1999\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2000\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n","\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './data/titanic/train.csv'"]}]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2018-10-28T07:48:20.005530Z","start_time":"2018-10-28T07:48:19.985459Z"},"id":"dIMMZZobbPeP"},"source":["train_data.head(10)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rjj0lHYjbPeQ"},"source":["test_data.head(10)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jX3Yc_HxbPeS"},"source":["# Preprocessing\n","- Pclass, Sex, Age, SibSp, Parch, Fare 총 6개의 feature를 사용하겠습니다.\n","- 별도의 feature engineering은 하지 않겠습니다.\n","- kaggle data이기 때문에 test_data의 \"Survived\" 열은 없습니다.\n","- 우리가 예측한 결과를 csv 파일로 제출하는 형태입니다."]},{"cell_type":"markdown","metadata":{"id":"JxGugBSebPeT"},"source":["### categorical variable 처리"]},{"cell_type":"code","metadata":{"id":"K48FXiY1bPeU"},"source":["train_data[\"Sex\"].head(10)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IqOsr-jsbPeU"},"source":["train_data[\"Sex\"] = train_data[\"Sex\"].map({\"male\": 1, \"female\": 0})\n","test_data[\"Sex\"] = test_data[\"Sex\"].map({\"male\": 1, \"female\": 0})"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"G_Yej7DybPeV"},"source":["train_data[\"Sex\"].head(10)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QmwsvSsxbPeV"},"source":["### 데이터셋 구성"]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2018-10-28T07:48:21.754377Z","start_time":"2018-10-28T07:48:21.739961Z"},"id":"0mWGmlM-bPeW"},"source":["data_X = train_data[[\"Pclass\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Fare\"]]\n","data_y = train_data[\"Survived\"]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"J8vdM8qTbPeW"},"source":["len(data_X)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8ssi3wHUbPeX"},"source":["train_X, test_X, train_y, test_y = train_test_split(data_X, data_y, test_size=0.3)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rV5ZXqYcbPeX"},"source":["len(train_X), len(data_X)*.7"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"s9_Wvzx5bPeY"},"source":["len(test_X), len(data_X)*.3"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-y0MK3h3bPeY"},"source":["### null 값 확인 (결측값)"]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2018-10-28T07:48:22.020698Z","start_time":"2018-10-28T07:48:22.006813Z"},"id":"LEdpyMEvbPeY"},"source":["print('Number of null in train_X:', train_X.isnull().sum())\n","print(\"\\n\",'Number of null in test_X:', test_X.isnull().sum())\n","print(\"\\n\",'Number of nullin train y:', train_y.isnull().sum())\n","print(\"\\n\",'Number of nullin train y:', test_y.isnull().sum())\n","\n","print(\"\\n\",np.mean(train_X[\"Age\"]))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"A16J7K_jbPeY"},"source":["- 간단하게 age와 fare의 na 값은 평균으로 대체"]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2018-10-28T07:48:23.836865Z","start_time":"2018-10-28T07:48:23.823969Z"},"scrolled":false,"id":"E9Ls0c0lbPeY"},"source":["pd.options.mode.chained_assignment = None\n","\n","train_X.loc[:,\"Age\"] = train_X.loc[:,\"Age\"].replace(np.nan,30)\n","test_X.loc[:,\"Age\"] = test_X.loc[:,\"Age\"].replace(np.nan,30)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2018-10-28T07:48:24.418285Z","start_time":"2018-10-28T07:48:24.406782Z"},"id":"PiDW3rlNbPeZ"},"source":["print('Number of null:', train_X.isnull().sum())\n","print(\"\\n\",'Number of null:', test_X.isnull().sum())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2018-10-28T07:48:26.498112Z","start_time":"2018-10-28T07:48:26.492656Z"},"id":"kGHwYg-vbPeZ"},"source":["train_y.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2018-10-28T07:48:27.198668Z","start_time":"2018-10-28T07:48:27.192577Z"},"id":"rtuNWEeEbPeZ"},"source":["len(train_X), len(test_X), len(train_y), len(test_y)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dV3Y1PC5bPeZ"},"source":["# Train model (PyTorch)\n","1. dataset, dataloader 정의\n","2. 모델 정의\n","3. 모델 학습 \n","4. 모델 평가"]},{"cell_type":"markdown","metadata":{"id":"pz7bvYSPbPeZ"},"source":["- train, test dataset을 출력할 수 있는 class를 만듭니다."]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2018-10-28T07:48:30.938583Z","start_time":"2018-10-28T07:48:30.931143Z"},"id":"Ze53fTkIbPeZ"},"source":["class simple_dataset(Dataset):\n","    \n","    def __init__(self, X_data, y_data):\n","        self.X_data = X_data\n","        self.y_data = y_data\n","        \n","    def __getitem__(self, index):\n","        return self.X_data[index], self.y_data[index]\n","        \n","    def __len__ (self):\n","        return len(self.X_data)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0bQ6b8_QbPea"},"source":["type(test_X)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2018-10-28T07:48:32.125111Z","start_time":"2018-10-28T07:48:32.117187Z"},"id":"iTTmOkOcbPea"},"source":["# 정규화합니다\n","scaler = StandardScaler()\n","train_data = simple_dataset(torch.FloatTensor(scaler.fit_transform(train_X.to_numpy())), torch.LongTensor(train_y.to_numpy()))\n","test_data = simple_dataset(torch.FloatTensor(scaler.fit_transform(test_X.to_numpy())), torch.LongTensor(test_y.to_numpy()))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vt8OOW_7bPea"},"source":["len(train_data), len(test_data)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2018-10-28T07:48:51.854783Z","start_time":"2018-10-28T07:48:51.849359Z"},"id":"rHGspM79bPea"},"source":["train_data.__getitem__(0)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uygHmaGDbPea"},"source":["train_data[0]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qK4pX6ASbPeb"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kLFSK0k8bPeb"},"source":["## Modeling"]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2018-10-28T08:24:00.698892Z","start_time":"2018-10-28T08:24:00.685532Z"},"id":"gc1UlS5ybPeb"},"source":["class Binary_Classification(nn.Module):\n","    \n","    def __init__(self, num_features, num_classes):\n","        super(Binary_Classification, self).__init__()\n","        \n","        self.Layer_1 = nn.Linear(num_features, 30)\n","        \n","        ################################################\n","        #  TODO    Layer 만들기                        #\n","        ################################################\n","        \n","        ################################################\n","        #  가능한 답은 하나가 아니므로 성능이 더 좋을  #\n","        #  법할 모델을 다양하게 시도해보시길 바랍니다  #\n","        ################################################\n","\n","        self.relu = nn.ReLU()\n","        \n","    def forward(self, inputs):\n","        \n","        x = self.Layer_1(inputs)\n","        x = self.relu(x)\n","        \n","        ################################################\n","        #  TODO       feature를 layer를 통과시키기     #\n","        ################################################\n","\n","        ################################################\n","        #  가능한 답은 하나가 아니므로 성능이 더 좋을  #\n","        #  법할 모델을 다양하게 시도해보시길 바랍니다  #\n","        ################################################\n","        \n","        x = self.Layer_out(x)\n","\n","        return x"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pGQc2LCKbPeb"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"e1PUlbHfbPeb"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FrZ560kLbPeb"},"source":["## Training"]},{"cell_type":"code","metadata":{"id":"Bqone0Y2bPeb"},"source":["EPOCHS = 3000\n","BATCH_SIZE = 891\n","\n","train_loader = DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)\n","test_loader = DataLoader(dataset=test_data, batch_size=1, shuffle=False)\n","\n","model = Binary_Classification(num_features=6, num_classes=2)\n","\n","criterion = nn.CrossEntropyLoss() # https://pytorch.org/docs/stable/nn.html\n","optimizer = optim.Adam(model.parameters(), lr=0.001)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ah9wBbeibPec"},"source":["### 데이터 사이즈 확인 "]},{"cell_type":"code","metadata":{"id":"Tv3vBuC4bPec"},"source":["for epoch in range(EPOCHS):\n","    for X_batch, y_batch in train_loader:\n","        print(X_batch.size(), y_batch.size())\n","        break\n","    break"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2018-10-28T08:26:29.145512Z","start_time":"2018-10-28T08:24:02.302520Z"},"scrolled":true,"id":"zJv6oWY-bPec"},"source":["loss_list = []\n","acc_list = []\n","for epoch in range(EPOCHS):\n","    for i, (X_batch, y_batch) in enumerate(train_loader):\n","        \n","        #Forward \n","        y_output = model(X_batch)\n","        loss = criterion(y_output, y_batch) #CELoss: The input is expected to contain raw, unnormalized scores for each class.\n","        \n","        #Backward\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","        \n","        #misc (acc 계산, etc) \n","        y_pred = torch.max(y_output, 1)[1]\n","        acc = accuracy_score(y_pred.data.cpu(), y_batch.data.cpu())\n","        loss_list.append(loss.item())\n","        acc_list.append(acc)\n","\n","    if (epoch+1) % 30 == 0:\n","        print('Epoch [{}/{}] Step [{}/{}] Loss: [{:.4f}] Train ACC [{:.2f}%]'.format(epoch+1, EPOCHS, \\\n","                                                                                   i+1, len(train_loader), loss.item(), acc*100))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"e3qILiMrbPec"},"source":["plt.plot(loss_list)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Apu0vOPEbPec"},"source":["plt.plot(acc_list)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XA4HBkCkbPec"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Hrze5UzxbPec"},"source":["## Test"]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2018-10-28T08:26:31.968976Z","start_time":"2018-10-28T08:26:31.839523Z"},"id":"6dSCL2O7bPec"},"source":["test_y_pred = []\n","test_acc_list = []\n","with torch.no_grad():\n","\n","    for X_batch, y_batch in test_loader:    \n","        #Forward\n","        y_output = model(X_batch)\n","        \n","        #misc (acc 계산, etc) \n","        y_pred = torch.max(y_output, 1)[1]\n","        test_y_pred.append(y_pred) ##\n","        \n","        acc = accuracy_score(y_pred.data.cpu(), y_batch.data.cpu())\n","        test_acc_list.append(acc)\n","    test_acc = np.mean(test_acc_list)\n","print('Test ACC: [{:.2f}%]'.format(test_acc*100))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3_ZF5Np7bPed"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ddAmd6SObPed"},"source":["len(test_y_pred), test_y_pred[:10]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OpcAU_eqbPed"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FQ1W_jVjdz3W"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HJlhsjj5bPed"},"source":["# *Alternative code*"]},{"cell_type":"code","metadata":{"id":"vWk8fjEobPed"},"source":["class Binary_Classification_layer(nn.Module):\n","    \n","    def __init__(self, num_features, num_classes):\n","        super(Binary_Classification_layer, self).__init__()\n","        \n","        self.Layer_1 = nn.Linear(num_feature, num_classes)\n","                     \n","        \n","        ################################################\n","        #       TODO                                   #\n","        ################################################\n","\n","        ################################################\n","        #  가능한 답은 하나가 아니므로 성능이 더 좋을  #\n","        #  법할 모델을 다양하게 시도해보시길 바랍니다  #\n","        ################################################\n","\n","\n","    def forward(self, inputs):\n","        \n","        x = self.Layer_1(inputs)      \n","        \n","        ################################################\n","        #       TODO                                   #\n","        ################################################    \n","        \n","        ################################################\n","        #  가능한 답은 하나가 아니므로 성능이 더 좋을  #\n","        #  법할 모델을 다양하게 시도해보시길 바랍니다  #\n","        ################################################\n","\n","\n","        return x"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nnDnz7Uvd6LK"},"source":["# *Assignment*\n","\n","- 본인만의 모델을 만들어 Test ACC 79%를 달성해보세요!"]},{"cell_type":"code","metadata":{"id":"NfJsasUdbPed"},"source":["EPOCHS = 1000\n","BATCH_SIZE = 200\n","\n","train_loader = DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)\n","test_loader = DataLoader(dataset=test_data, batch_size=1, shuffle=False)\n","\n","model = Binary_Classification_layer(num_features=6, num_classes=2)\n","\n","criterion = nn.CrossEntropyLoss() # https://pytorch.org/docs/stable/nn.html\n","optimizer = optim.Adam(model.parameters(), lr=0.001)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"W9_R_auBbPed"},"source":["train_loss_list = []\n","train_acc_list = []\n","\n","test_acc_list = []\n","\n","for epoch in range(EPOCHS):\n","    # train\n","    for \n","        ################################################\n","        #       TODO                                   #\n","        ################################################ \n","        X_batch = \n","        y_batch = \n","        \n","        #Forward \n","        y_output = \n","        loss =  #CELoss: The input is expected to contain raw, unnormalized scores for each class.\n","        \n","        #Backward\n","        optimizer\n","        loss\n","        optimizer\n","        \n","        #misc (acc 계산, etc) \n","        y_pred = \n","        train_acc =\n","        \n","        train_loss_list\n","        train_acc_list\n","\n","        ################################################\n","        #  가능한 답은 하나가 아니므로 성능이 더 좋을  #\n","        #  법할 모델을 다양하게 시도해보시길 바랍니다  #\n","        ################################################\n","\n","    \n","        \n","    # test\n","    with torch.no_grad():\n","        ################################################\n","        #       TODO                                   #\n","        ################################################ \n","        #Forward\n","\n","        \n","        #misc (acc 계산, etc) \n","\n","        ################################################\n","        #  가능한 답은 하나가 아니므로 성능이 더 좋을  #\n","        #  법할 모델을 다양하게 시도해보시길 바랍니다  #\n","        ################################################\n","\n","    \n","    if (epoch+1) % 30 == 0:\n","        print('Epoch [{}/{}] Step [{}/{}] Loss: [{:.4f}] Train avg ACC [{:.2f}%] Test ACC [{:.2f}%]'.format(epoch+1, EPOCHS, \\\n","                                                                                   i+1, len(train_loader), np.mean(train_loss_list), \\\n","                                                                                                        np.mean(train_acc_list)*100, np.mean(test_acc_list)*100))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7xsNHdndbPee"},"source":[""],"execution_count":null,"outputs":[]}]}