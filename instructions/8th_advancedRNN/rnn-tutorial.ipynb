{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"rnn-tutorial.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"qESKgCBJNgj1"},"source":["# Recurrent Neural Networks\n","1. Build RNN to predict time-series data.\n","2. Build LSTM to predict time-series data. (Assignment)"]},{"cell_type":"markdown","metadata":{"id":"Z-8fB8zvpzB0"},"source":["## Import dependencies"]},{"cell_type":"code","metadata":{"id":"HNABhe1DNaAy"},"source":["import torch \n","import torch.nn as nn\n","\n","import math\n","from sklearn.metrics import mean_squared_error\n","from sklearn.preprocessing import MinMaxScaler\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","import sys\n","sys.path.insert(0, './')\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Jgxj-tzlp1QU"},"source":["## Prepare dataset"]},{"cell_type":"code","metadata":{"id":"zT24_KDxp2m4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1633573711286,"user_tz":-540,"elapsed":270,"user":{"displayName":"이상현","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj8RilMUXcAxDmd3aY6OO3wDTdv_Nij1Cvs-8Zi8Q=s64","userId":"13289989320166456989"}},"outputId":"42d8de4c-9a71-4016-cc55-2029b00dcab4"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","metadata":{"id":"aAxEF5xXp4PR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1633573714186,"user_tz":-540,"elapsed":217,"user":{"displayName":"이상현","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj8RilMUXcAxDmd3aY6OO3wDTdv_Nij1Cvs-8Zi8Q=s64","userId":"13289989320166456989"}},"outputId":"eaea5b0d-15f9-4aec-a860-528fcb399879"},"source":["%cd /content/drive/MyDrive/Colab\\ Notebooks/"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Colab Notebooks\n"]}]},{"cell_type":"code","metadata":{"id":"uKIvv7E9p55u","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1633573714768,"user_tz":-540,"elapsed":334,"user":{"displayName":"이상현","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj8RilMUXcAxDmd3aY6OO3wDTdv_Nij1Cvs-8Zi8Q=s64","userId":"13289989320166456989"}},"outputId":"1ff672d2-7e8e-4681-f922-a1d5882aacee"},"source":["!pwd"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Colab Notebooks\n"]}]},{"cell_type":"code","metadata":{"id":"ghohK10Bxj6L"},"source":["# make predictions\n","y_test_pred = model(x_test)\n","y_test_pred"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fgzgFpvYp3pS"},"source":["# Bidirectional RNN"]},{"cell_type":"code","metadata":{"id":"wfdAq4f6lZ6E"},"source":["import torch \n","import torch.nn as nn\n","import torchvision\n","import torchvision.transforms as transforms\n","\n","\n","# Device configuration\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","# Hyper-parameters\n","sequence_length = 28\n","input_size = 28\n","hidden_size = 128\n","num_layers = 2\n","num_classes = 10\n","batch_size = 100\n","num_epochs = 1\n","learning_rate = 0.003\n","\n","# MNIST dataset\n","train_dataset = torchvision.datasets.MNIST(root='./data/',\n","                                           train=True, \n","                                           transform=transforms.ToTensor(),\n","                                           download=True)\n","\n","test_dataset = torchvision.datasets.MNIST(root='./data/',\n","                                          train=False, \n","                                          transform=transforms.ToTensor())\n","\n","# Data loader\n","train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n","                                           batch_size=batch_size, \n","                                           shuffle=True)\n","\n","test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n","                                          batch_size=batch_size, \n","                                          shuffle=False)\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BEfi4FRrlZ-6"},"source":["# Bidirectional recurrent neural network (many-to-one)\n","class BiRNN(nn.Module):\n","    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n","        super(BiRNN, self).__init__()\n","        self.hidden_size = hidden_size\n","        self.num_layers = num_layers\n","        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, bidirectional=True)\n","        self.fc = nn.Linear(hidden_size*2, num_classes)  # 2 for bidirection\n","    \n","    def forward(self, x):\n","        # Set initial states\n","        h0 = torch.zeros(self.num_layers*2, x.size(0), self.hidden_size).to(device) # 2 for bidirection \n","        c0 = torch.zeros(self.num_layers*2, x.size(0), self.hidden_size).to(device)\n","        \n","        # Forward propagate LSTM\n","        out, a = self.lstm(x, (h0, c0))  # out: tensor of shape (batch_size, seq_length, hidden_size*2)\n","        print(a[0].shape, x.shape)\n","        # Decode the hidden state of the last time step\n","        out = self.fc(out[:, -1, :])\n","        return out\n","\n","model = BiRNN(input_size, hidden_size, num_layers, num_classes).to(device)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"u8uqlztTlaBF","executionInfo":{"status":"ok","timestamp":1633574446134,"user_tz":-540,"elapsed":280,"user":{"displayName":"이상현","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj8RilMUXcAxDmd3aY6OO3wDTdv_Nij1Cvs-8Zi8Q=s64","userId":"13289989320166456989"}},"outputId":"f85ac5be-5839-4529-ec2a-92c16265ef59"},"source":["# Loss and optimizer\n","criterion = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n","    \n","# Train the model\n","total_step = len(train_loader)\n","for epoch in range(num_epochs):\n","    for i, (images, labels) in enumerate(train_loader):\n","        images = images.reshape(-1, sequence_length, input_size).to(device)\n","        labels = labels.to(device)\n","        \n","        # Forward pass\n","        outputs = model(images)\n","        loss = criterion(outputs, labels)\n","        \n","        # Backward and optimize\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","        if (i+1) % 100 == 0:\n","            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n","                   .format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n","# Test the model\n","with torch.no_grad():\n","    correct = 0\n","    total = 0\n","    for images, labels in test_loader:\n","        images = images.reshape(-1, sequence_length, input_size).to(device)\n","        labels = labels.to(device)\n","        outputs = model(images)\n","        _, predicted = torch.max(outputs.data, 1)\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum().item()\n","\n","    print('Test Accuracy of the model on the 10000 test images: {} %'.format(100 * correct / total)) \n","\n","# Save the model checkpoint\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([4, 100, 128]) torch.Size([100, 28, 28])\n"]}]},{"cell_type":"markdown","metadata":{"id":"aN905RoTqCL_"},"source":["# GRU"]},{"cell_type":"code","metadata":{"id":"pGOgzfu-laF2"},"source":["class Gru(nn.Module):\n","    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n","        super(Gru, self).__init__()\n","        self.hidden_size = hidden_size\n","        self.num_layers = num_layers\n","        self.gru = nn.GRU(input_size, hidden_size, num_layers, batch_first=True, bidirectional=True)\n","        self.fc = nn.Linear(hidden_size*2, num_classes)  # 2 for bidirection\n","    \n","    def forward(self, x):\n","        # Set initial states\n","        h0 = torch.zeros(self.num_layers*2, x.size(0), self.hidden_size).to(device) # 2 for bidirection \n","        # c0 = torch.zeros(self.num_layers*2, x.size(0), self.hidden_size).to(device)\n","        # Forward propagate LSTM\n","        out, _ = self.gru(x, h0)  # out: tensor of shape (batch_size, seq_length, hidden_size*2)\n","        # Decode the hidden state of the last time step\n","        out = self.fc(out[:, -1, :])\n","        return out\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"epEx2ErHqJTE"},"source":["sequence_length = 28\n","input_size = 28\n","hidden_size = 128\n","num_layers = 2\n","num_classes = 10\n","batch_size = 100\n","num_epochs = 1\n","learning_rate = 0.003\n","\n","model = Gru(input_size, hidden_size, num_layers, num_classes).to(device)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"k2dELHElqPv8"},"source":["# Loss and optimizer\n","criterion = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n","    \n","# Train the model\n","total_step = len(train_loader)\n","for epoch in range(num_epochs):\n","    for i, (images, labels) in enumerate(train_loader):\n","        images = images.reshape(-1, sequence_length, input_size).to(device)\n","        labels = labels.to(device)\n","        \n","        # Forward pass\n","        outputs = model(images)\n","        loss = criterion(outputs, labels)\n","        \n","        # Backward and optimize\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","        if (i+1) % 100 == 0:\n","            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n","                   .format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n","# Test the model\n","with torch.no_grad():\n","    correct = 0\n","    total = 0\n","    for images, labels in test_loader:\n","        images = images.reshape(-1, sequence_length, input_size).to(device)\n","        labels = labels.to(device)\n","        outputs = model(images)\n","        _, predicted = torch.max(outputs.data, 1)\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum().item()\n","\n","    print('Test Accuracy of the model on the 10000 test images: {} %'.format(100 * correct / total)) \n","\n","# Save the model checkpoint\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"O0tkyiikt_dj"},"source":["# RNN with Text"]},{"cell_type":"code","metadata":{"id":"L1-vXgryqTZc"},"source":["\n","sentences = [\"i like dog\", \"i love coffee\", \"i hate milk\", \"you like cat\", \"you love milk\", \"you hate coffee\"]\n","dtype = torch.float\n","\n","\"\"\"\n","Word Processing\n","\"\"\"\n","word_list = list(set(\" \".join(sentences).split()))\n","word_dict = {w: i for i, w in enumerate(word_list)}\n","number_dict = {i: w for i, w in enumerate(word_list)}\n","n_class = len(word_dict)\n","# \"\"\"\n","# TextRNN Parameter\n","# \"\"\"\n","batch_size = len(sentences)\n","n_step = 2  # 학습 하려고 하는 문장의 길이 - 1\n","n_hidden = 5  # 은닉층 사이즈\n","\n","def make_batch(sentences):\n","  input_batch = []\n","  target_batch = []\n","\n","  for sen in sentences:\n","    word = sen.split()\n","    input = [word_dict[n] for n in word[:-1]]\n","    target = word_dict[word[-1]]\n","\n","    input_batch.append(np.eye(n_class)[input])  # One-Hot Encoding\n","    target_batch.append(target)\n","  \n","  return input_batch, target_batch\n","\n","input_batch, target_batch = make_batch(sentences)\n","input_batch = torch.tensor(input_batch, dtype=torch.float32, requires_grad=True)\n","target_batch = torch.tensor(target_batch, dtype=torch.int64)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ptMv917EseMR","executionInfo":{"status":"ok","timestamp":1633576851890,"user_tz":-540,"elapsed":218,"user":{"displayName":"이상현","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj8RilMUXcAxDmd3aY6OO3wDTdv_Nij1Cvs-8Zi8Q=s64","userId":"13289989320166456989"}},"outputId":"2a83646d-a90c-4e43-f74c-69b512ef186c"},"source":["\n","\n","# \"\"\"\n","# TextRNN\n","# \"\"\"\n","class TextRNN(nn.Module):\n","  def __init__(self):\n","    super(TextRNN, self).__init__()\n","\n","    self.rnn = nn.RNN(input_size=n_class, hidden_size=n_hidden, dropout=0.3, batch_first= True)\n","    self.W = nn.Parameter(torch.randn([ n_hidden, n_class]).type(dtype))\n","    self.b = nn.Parameter(torch.randn([n_class]).type(dtype))\n","    self.Softmax = nn.Softmax(dim=1)\n","\n","  def forward(self, X):\n","    # X = X.transpose(0, 1)\n","    hidden = torch.zeros(1, batch_size, n_hidden, requires_grad=True)\n","    outputs, hidden = self.rnn(X, hidden)\n","    outputs = outputs[:,-1,:]  # 최종 예측 Hidden Layer\n","    model = torch.mm(outputs, self.W) + self.b  # 최종 예측 최종 출력 층\n","    return model\n","\t\n","\n","# \"\"\"\n","# Training\n","# \"\"\"\n","model = TextRNN()\n","criterion = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n","\n","for epoch in range(1):\n","  output = model(input_batch)\n","  loss = criterion(output, target_batch)\n","\n","  if (epoch + 1) % 100 == 0:\n","    print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.6f}'.format(loss))\n","  \n","  optimizer.zero_grad()\n","  loss.backward()\n","  optimizer.step()\n","\n","input = [sen.split()[:2] for sen in sentences]\n","\n","hidden = torch.zeros(1, batch_size, n_hidden, requires_grad=True)\n","predict = model(input_batch).data.max(1, keepdim=True)[1]\n","print([sen.split()[:2] for sen in sentences], '->', [number_dict[n.item()] for n in predict.squeeze()])\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[['i', 'like'], ['i', 'love'], ['i', 'hate'], ['you', 'like'], ['you', 'love'], ['you', 'hate']] -> ['coffee', 'coffee', 'coffee', 'coffee', 'coffee', 'coffee']\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:65: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n","  \"num_layers={}\".format(dropout, num_layers))\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sZF3xkh_tUb9","executionInfo":{"status":"ok","timestamp":1633576893925,"user_tz":-540,"elapsed":242,"user":{"displayName":"이상현","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj8RilMUXcAxDmd3aY6OO3wDTdv_Nij1Cvs-8Zi8Q=s64","userId":"13289989320166456989"}},"outputId":"c75f6764-efc7-4d13-f0da-3000dba87b6b"},"source":["target_batch"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([3, 6, 4, 1, 4, 6])"]},"metadata":{},"execution_count":91}]},{"cell_type":"code","metadata":{"id":"4XNOd6tQxXOC"},"source":[""],"execution_count":null,"outputs":[]}]}